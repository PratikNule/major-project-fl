import torch
import torch.nn as nn
import torch.nn.functional as F
import joblib
import os

DATA_DIR = '/Users/ayushpatne/Developer/FL_Major/project/data/'

def get_model_input_features():
    """Loads feature columns to determine model input size."""
    try:
        feature_columns = joblib.load(os.path.join(DATA_DIR, 'feature_columns.joblib'))
        return len(feature_columns)
    except FileNotFoundError:
        # Fallback or error, this should be generated by data_split.py
        print("Error: feature_columns.joblib not found. Run data_split.py first.")
        print("Defaulting to 47 features, this might be incorrect.")
        # Based on Kaggle dataset description, there are many columns.
        # A more robust way is to ensure data_split.py runs first.
        # The original dataset has around 48 columns before 'FLAG' and identifiers.
        # Let's assume a number after preprocessing. This MUST match data_split.py output.
        return 47 # Placeholder, update this if necessary or ensure file exists

class FraudDetectionNet(nn.Module):
    def __init__(self, input_features):
        super(FraudDetectionNet, self).__init__()
        self.fc1 = nn.Linear(input_features, 64)
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        self.dropout = nn.Dropout(0.2) # Added dropout for regularization

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = F.relu(self.fc2(x))
        x = self.dropout(x)
        x = torch.sigmoid(self.fc3(x))
        return x

if __name__ == '__main__':
    # Example usage:
    num_features = get_model_input_features()
    model = FraudDetectionNet(input_features=num_features)
    print(model)
    # Test with dummy input
    dummy_input = torch.randn(1, num_features)
    output = model(dummy_input)
    print("Dummy input shape:", dummy_input.shape)
    print("Output shape:", output.shape)
    print("Output value:", output.item())