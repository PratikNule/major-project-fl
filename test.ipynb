{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethereum Fraud Detection Data Processing\n",
    "\n",
    "## Introduction\n",
    "This notebook processes a dataset for detecting fraudulent Ethereum accounts based on transaction patterns, ERC20 token activities, and account behaviors. The dataset is unbalanced, and we'll analyze, preprocess, and split it for federated learning experiments.\n",
    "\n",
    "## Objective\n",
    "The goal is to predict fraudulent Ethereum transactions using historical transaction data. This is a binary classification problem where:\n",
    "- **FLAG = 1** indicates fraud\n",
    "- **FLAG = 0** indicates non-fraud\n",
    "\n",
    "## Federated Learning Setup\n",
    "We'll split the data into N non-IID datasets with different fraud ratios to simulate real-world client data distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.13.2)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"/Users/ayushpatne/Developer/FL_Major/venv/bin/python\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!source venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade scikit-learn\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.base import BaseEstimator\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Define key parameters for data processing and federated learning setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATASET_PATH = '/Users/ayushpatne/Developer/FL_Major/transaction_dataset.csv'\n",
    "OUTPUT_DATA_DIR = '/Users/ayushpatne/Developer/FL_Major/project/data/'\n",
    "NUM_CLIENTS = 3\n",
    "\n",
    "# Client fraud ratios: different proportions to create non-IID distribution\n",
    "# These are target fraud ratios for the *entirety* of each client's data (train+test)\n",
    "CLIENT_FRAUD_CONFIG = {\n",
    "    0: {'fraud_ratio': 0.05, 'name': 'client_1'},  # 5% fraud\n",
    "    1: {'fraud_ratio': 0.10, 'name': 'client_2'},  # 10% fraud\n",
    "    2: {'fraud_ratio': 0.20, 'name': 'client_3'}   # 20% fraud\n",
    "}\n",
    "\n",
    "TEST_SIZE = 0.2  # Test set size for each client's data\n",
    "RANDOM_STATE = 42  # For reproducibility\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(OUTPUT_DATA_DIR):\n",
    "    os.makedirs(OUTPUT_DATA_DIR)\n",
    "\n",
    "print(f\"Configuration Summary:\")\n",
    "print(f\"- Number of Clients: {NUM_CLIENTS}\")\n",
    "print(f\"- Test Set Size: {TEST_SIZE * 100}%\")\n",
    "print(f\"- Client Fraud Distribution:\")\n",
    "for client_id, config in CLIENT_FRAUD_CONFIG.items():\n",
    "    print(f\"  * {config['name']}: {config['fraud_ratio'] * 100}% fraud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "This section loads the Ethereum transaction dataset and performs necessary preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"Loads and preprocesses the Ethereum fraud dataset.\"\"\"\n",
    "    print(f\"Loading data from {file_path}...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Initial data exploration\n",
    "    print(f\"\\nInitial dataset shape: {df.shape}\")\n",
    "    print(f\"\\nData types:\\n{df.dtypes}\")\n",
    "    \n",
    "    # Check class distribution before preprocessing\n",
    "    if 'FLAG' in df.columns:\n",
    "        fraud_count = df['FLAG'].sum()\n",
    "        total_count = len(df)\n",
    "        fraud_ratio = fraud_count / total_count\n",
    "        print(f\"\\nInitial class distribution:\")\n",
    "        print(f\"- Total records: {total_count}\")\n",
    "        print(f\"- Fraud records: {fraud_count} ({fraud_ratio:.2%})\")\n",
    "        print(f\"- Non-fraud records: {total_count - fraud_count} ({1-fraud_ratio:.2%})\")\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df = df.drop(columns=['Index', 'Address'], errors='ignore')\n",
    "\n",
    "    # Clean column names (remove leading/trailing spaces, replace special chars)\n",
    "    df.columns = [\"_\".join(c if c.isalnum() else \"_\" for c in str(x)) for x in df.columns]\n",
    "    df = df.rename(columns={'FLAG': 'FLAG'})  # Ensure FLAG column is correctly named\n",
    "\n",
    "    # Identify potential categorical columns\n",
    "    categorical_cols = [\n",
    "        'ERC20_most_sent_token_type',\n",
    "        'ERC20_most_rec_token_type'\n",
    "    ]\n",
    "    \n",
    "    # Implement robust categorical feature handling\n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns:\n",
    "            if df[col].dtype == 'object' or df[col].dtype == 'category':\n",
    "                df[col] = df[col].astype(str)  # Ensure it's string type\n",
    "                df[col].fillna('Unknown', inplace=True)\n",
    "                le = LabelEncoder()\n",
    "                df[col] = le.fit_transform(df[col])\n",
    "                print(f\"Encoded {col} with {len(le.classes_)} unique values\")\n",
    "            else:\n",
    "                print(f\"Column {col} is not of object/category type, it's {df[col].dtype}. Skipping label encoding.\")\n",
    "        else:\n",
    "            print(f\"Categorical column {col} not found in dataframe.\")\n",
    "\n",
    "    # Fill NaN values for numeric columns with mean\n",
    "    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "    if 'FLAG' in numeric_cols:\n",
    "        numeric_cols.remove('FLAG')\n",
    "    \n",
    "    # Count NaNs before filling\n",
    "    nan_counts = df[numeric_cols].isna().sum()\n",
    "    print(f\"\\nNaN counts before filling:\")\n",
    "    print(nan_counts[nan_counts > 0])\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "    # Ensure all remaining object columns that should be numeric are converted\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object' and col != 'FLAG':\n",
    "            df[col] = pd.to_numeric(df[col].str.replace(',', ''), errors='coerce')\n",
    "            df[col].fillna(0, inplace=True)\n",
    "\n",
    "    # Drop rows where FLAG is NaN if any (should not happen if FLAG is 0/1)\n",
    "    df.dropna(subset=['FLAG'], inplace=True)\n",
    "    df['FLAG'] = df['FLAG'].astype(int)\n",
    "\n",
    "    # Remove duplicate rows\n",
    "    dupes_before = len(df)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    dupes_after = len(df)\n",
    "    print(f\"\\nRemoved {dupes_before - dupes_after} duplicate rows\")\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop(columns=['FLAG'])\n",
    "    y = df['FLAG']\n",
    "\n",
    "    # Identify numeric features for scaling\n",
    "    numeric_features_to_scale = X.select_dtypes(include=np.number).columns.tolist()\n",
    "    \n",
    "    # Scale numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X[numeric_features_to_scale] = scaler.fit_transform(X[numeric_features_to_scale])\n",
    "\n",
    "    # Save the scaler and feature columns\n",
    "    joblib.dump(scaler, os.path.join(OUTPUT_DATA_DIR, 'scaler.joblib'))\n",
    "    joblib.dump(X.columns.tolist(), os.path.join(OUTPUT_DATA_DIR, 'feature_columns.joblib'))\n",
    "    \n",
    "    print(f\"\\nPreprocessed data summary:\")\n",
    "    print(f\"- Final dataset shape: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "    print(f\"- Features: {X.shape[1]}\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "X, y = load_and_preprocess_data(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Let's explore the preprocessed data to better understand its characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics for features\n",
    "print(\"Feature statistics:\")\n",
    "X.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x=y)\n",
    "plt.title('Class Distribution Before Balancing')\n",
    "plt.xlabel('Fraud Flag (0=Non-Fraud, 1=Fraud)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Add count labels\n",
    "for i, count in enumerate(y.value_counts()):\n",
    "    plt.text(i, count + 50, f\"{count} ({count/len(y):.1%})\", ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correlation heatmap for selected features\n",
    "plt.figure(figsize=(12, 10))\n",
    "# Select top 15 features with highest correlation to FLAG\n",
    "full_df = pd.concat([X, y], axis=1)\n",
    "corr_with_fraud = abs(full_df.corr()['FLAG']).sort_values(ascending=False)\n",
    "top_corr_features = corr_with_fraud.index[:16]  # Include FLAG and top 15 features\n",
    "\n",
    "# Create correlation matrix for these features\n",
    "corr_matrix = full_df[top_corr_features].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap (Top 15 Features)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Missing Values Heatmap')\n",
    "sns.heatmap(full_df.isnull(), cbar=False, cmap='viridis', yticklabels=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total missing values: {full_df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of a few important numeric features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Distribution of Key Features by Fraud Class')\n",
    "\n",
    "# Pick 4 interesting features\n",
    "top_features = corr_with_fraud.index[1:5]  # Skip FLAG itself\n",
    "\n",
    "for i, feature in enumerate(top_features):\n",
    "    row, col = i // 2, i % 2\n",
    "    sns.histplot(data=full_df, x=feature, hue='FLAG', bins=30, kde=True, ax=axes[row, col])\n",
    "    axes[row, col].set_title(f'Distribution of {feature}')\n",
    "    axes[row, col].set_xlabel(feature)\n",
    "    axes[row, col].set_ylabel('Frequency')\n",
    "    axes[row, col].legend(['Non-Fraud', 'Fraud'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Balancing with SMOTE\n",
    "\n",
    "The dataset is imbalanced with respect to the fraud class. We'll use SMOTE (Synthetic Minority Over-sampling Technique) to balance it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(X, y):\n",
    "    \"\"\"Balances the dataset using SMOTE.\"\"\"\n",
    "    print(f\"Original class distribution:\")\n",
    "    print(f\"- Class 0 (Non-Fraud): {sum(y == 0)} samples ({sum(y == 0)/len(y):.2%})\")\n",
    "    print(f\"- Class 1 (Fraud): {sum(y == 1)} samples ({sum(y == 1)/len(y):.2%})\")\n",
    "    \n",
    "    smote = SMOTE(random_state=RANDOM_STATE)\n",
    "    X_balanced, y_balanced = smote.fit_resample(X, y)\n",
    "    \n",
    "    print(f\"\\nBalanced class distribution:\")\n",
    "    print(f\"- Class 0 (Non-Fraud): {sum(y_balanced == 0)} samples ({sum(y_balanced == 0)/len(y_balanced):.2%})\")\n",
    "    print(f\"- Class 1 (Fraud): {sum(y_balanced == 1)} samples ({sum(y_balanced == 1)/len(y_balanced):.2%})\")\n",
    "    print(f\"- Total samples after balancing: {len(y_balanced)}\")\n",
    "    return X_balanced, y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to balance the dataset\n",
    "X_balanced, y_balanced = balance_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class distribution before and after balancing\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Before balancing\n",
    "sns.countplot(x=y, ax=ax[0])\n",
    "ax[0].set_title('Class Distribution Before Balancing')\n",
    "ax[0].set_xlabel('Fraud Flag (0=Non-Fraud, 1=Fraud)')\n",
    "ax[0].set_ylabel('Count')\n",
    "for i, count in enumerate(y.value_counts()):\n",
    "    ax[0].text(i, count + 50, f\"{count} ({count/len(y):.1%})\", ha='center')\n",
    "\n",
    "# After balancing\n",
    "sns.countplot(x=y_balanced, ax=ax[1])\n",
    "ax[1].set_title('Class Distribution After Balancing (SMOTE)')\n",
    "ax[1].set_xlabel('Fraud Flag (0=Non-Fraud, 1=Fraud)')\n",
    "ax[1].set_ylabel('Count')\n",
    "for i, count in enumerate(pd.Series(y_balanced).value_counts()):\n",
    "    ax[1].text(i, count + 50, f\"{count} ({count/len(y_balanced):.1%})\", ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Non-IID Data Splits for Federated Learning\n",
    "\n",
    "This function creates heterogeneous data splits for federated learning clients with varying fraud ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_non_iid_splits(X, y, num_clients, client_fraud_config, test_size, random_state):\n",
    "    \"\"\"Creates non-IID data splits for clients based on fraud ratios.\"\"\"\n",
    "    data = X.copy()\n",
    "    data['FLAG'] = y\n",
    "\n",
    "    fraud_data = data[data['FLAG'] == 1]\n",
    "    non_fraud_data = data[data['FLAG'] == 0]\n",
    "    \n",
    "    print(f\"Total data distribution:\")\n",
    "    print(f\"- Fraud samples: {len(fraud_data)}\")\n",
    "    print(f\"- Non-fraud samples: {len(non_fraud_data)}\")\n",
    "    print(f\"- Total samples: {len(data)}\")\n",
    "\n",
    "    client_data_indices = [[] for _ in range(num_clients)]\n",
    "    \n",
    "    # Shuffle data to ensure randomness before splitting\n",
    "    fraud_data = fraud_data.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    non_fraud_data = non_fraud_data.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "    # Distribute data to clients based on target fraud ratios\n",
    "    available_fraud_indices = list(fraud_data.index)\n",
    "    available_non_fraud_indices = list(non_fraud_data.index)\n",
    "\n",
    "    # Calculate total samples per client (approximate)\n",
    "    total_samples = len(data)\n",
    "    samples_per_client_approx = total_samples // num_clients\n",
    "\n",
    "    for client_id in range(num_clients):\n",
    "        target_fraud_ratio = client_fraud_config[client_id]['fraud_ratio']\n",
    "        \n",
    "        # Determine number of fraud samples for this client\n",
    "        num_fraud_samples_for_client = int(samples_per_client_approx * target_fraud_ratio)\n",
    "        num_fraud_samples_for_client = min(num_fraud_samples_for_client, len(available_fraud_indices))\n",
    "\n",
    "        # Determine number of non-fraud samples\n",
    "        num_non_fraud_samples_for_client = samples_per_client_approx - num_fraud_samples_for_client\n",
    "        num_non_fraud_samples_for_client = min(num_non_fraud_samples_for_client, len(available_non_fraud_indices))\n",
    "        num_non_fraud_samples_for_client = max(0, num_non_fraud_samples_for_client)  # Ensure non-negative\n",
    "\n",
    "        client_fraud_sample_indices = available_fraud_indices[:num_fraud_samples_for_client]\n",
    "        client_non_fraud_sample_indices = available_non_fraud_indices[:num_non_fraud_samples_for_client]\n",
    "        \n",
    "        client_data_indices[client_id].extend(fraud_data.iloc[client_fraud_sample_indices].index.tolist())\n",
    "        client_data_indices[client_id].extend(non_fraud_data.iloc[client_non_fraud_sample_indices].index.tolist())\n",
    "        \n",
    "        # Update available indices\n",
    "        available_fraud_indices = available_fraud_indices[num_fraud_samples_for_client:]\n",
    "        available_non_fraud_indices = available_non_fraud_indices[num_non_fraud_samples_for_client:]\n",
    "\n",
    "    # Handle remaining data - distribute to the last client\n",
    "    if available_fraud_indices:\n",
    "        client_data_indices[-1].extend(fraud_data.iloc[available_fraud_indices].index.tolist())\n",
    "    if available_non_fraud_indices:\n",
    "        client_data_indices[-1].extend(non_fraud_data.iloc[available_non_fraud_indices].index.tolist())\n",
    "\n",
    "    client_datasets = []\n",
    "    for client_id in range(num_clients):\n",
    "        client_df = data.iloc[client_data_indices[client_id]].reset_index(drop=True)\n",
    "        \n",
    "        if len(client_df) == 0:\n",
    "            print(f\"Warning: Client {client_id} has no data.\")\n",
    "            client_train_df = pd.DataFrame(columns=data.columns)\n",
    "            client_test_df = pd.DataFrame(columns=data.columns)\n",
    "        elif len(client_df) < 2:\n",
    "            print(f\"Warning: Client {client_id} has only {len(client_df)} samples. Using all for training.\")\n",
    "            client_train_df = client_df\n",
    "            client_test_df = pd.DataFrame(columns=data.columns)  # Empty test set\n",
    "        else:\n",
    "            client_X = client_df.drop(columns=['FLAG'])\n",
    "            client_y = client_df['FLAG']\n",
    "            # Stratify if possible, otherwise random split\n",
    "            try:\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    client_X, client_y, test_size=test_size, random_state=random_state, stratify=client_y\n",
    "                )\n",
    "            except ValueError:  # Happens if a class has too few samples for stratification\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    client_X, client_y, test_size=test_size, random_state=random_state\n",
    "                )\n",
    "\n",
    "            client_train_df = X_train.copy()\n",
    "            client_train_df['FLAG'] = y_train\n",
    "            client_test_df = X_test.copy()\n",
    "            client_test_df['FLAG'] = y_test\n",
    "        \n",
    "        client_datasets.append({\n",
    "            'name': client_fraud_config[client_id]['name'],\n",
    "            'train': client_train_df,\n",
    "            'test': client_test_df\n",
    "        })\n",
    "        \n",
    "        # Create output directory for client data visualizations\n",
    "        client_output_dir = os.path.join(OUTPUT_DATA_DIR, client_fraud_config[client_id]['name'])\n",
    "        if not os.path.exists(client_output_dir):\n",
    "            os.makedirs(client_output_dir)\n",
    "        \n",
    "        # Calculate and print client data statistics\n",
    "        actual_fraud_ratio_train = client_train_df['FLAG'].mean() if len(client_train_df) > 0 else 0\n",
    "        actual_fraud_ratio_test = client_test_df['FLAG'].mean() if len(client_test_df) > 0 else 0\n",
    "        \n",
    "        print(f\"\\nClient {client_id} ({client_fraud_config[client_id]['name']}):\")\n",
    "        print(f\"- Train size: {len(client_train_df)} samples\")\n",
    "        print(f\"- Test size: {len(client_test_df)} samples\")\n",
    "        print(f\"- Train Fraud Ratio: {actual_fraud_ratio_train:.3f} ({actual_fraud_ratio_train:.1%})\")\n",
    "        print(f\"- Test Fraud Ratio: {actual_fraud_ratio_test:.3f} ({actual_fraud_ratio_test:.1%})\")\n",
    "\n",
    "    return client_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create non-IID client splits\n",
    "print(\"Creating non-IID client splits...\")\n",
    "client_datasets = create_non_iid_splits(X_balanced, y_balanced, NUM_CLIENTS, CLIENT_FRAUD_CONFIG, TEST_SIZE, RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Client Data Distributions\n",
    "\n",
    "Let's visualize how the data is distributed across clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud ratio distribution across clients\n",
    "client_names = []\n",
    "train_fraud_ratios = []\n",
    "test_fraud_ratios = []\n",
    "train_sizes = []\n",
    "test_sizes = []\n",
    "\n",
    "for client in client_datasets:\n",
    "    client_names.append(client['name'])\n",
    "    train_fraud_ratios.append(client['train']['FLAG'].mean() if len(client['train']) > 0 else 0)\n",
    "    test_fraud_ratios.append(client['test']['FLAG'].mean() if len(client['test']) > 0 else 0)\n",
    "    train_sizes.append(len(client['train']))\n",
    "    test_sizes.append(len(client['test']))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].bar(client_names, train_fraud_ratios, color='blue')\n",
    "ax[0].set_title('Training Fraud Ratios')\n",
    "ax[0].set_xlabel('Client')\n",
    "ax[0].set_ylabel('Fraud Ratio')\n",
    "\n",
    "ax[1].bar(client_names, test_fraud_ratios, color='green')\n",
    "ax[1].set_title('Testing Fraud Ratios')\n",
    "ax[1].set_xlabel('Client')\n",
    "ax[1].set_ylabel('Fraud Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Client Data Distributions\n",
    "\n",
    "Let's visualize how the data is distributed across clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud ratio distribution across clients\n",
    "client_names = []\n",
    "train_fraud_ratios = []\n",
    "test_fraud_ratios = []\n",
    "train_sizes = []\n",
    "test_sizes = []\n",
    "\n",
    "for client in client_datasets:\n",
    "    client_names.append(client['name'])\n",
    "    train_fraud_ratios.append(client['train']['FLAG'].mean() if len(client['train']) > 0 else 0)\n",
    "    test_fraud_ratios.append(client['test']['FLAG'].mean() if len(client['test']) > 0 else 0)\n",
    "    train_sizes.append(len(client['train']))\n",
    "    test_sizes.append(len(client['test']))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].bar(client_names, train_fraud_ratios, color='blue')\n",
    "ax[0].set_title('Training Fraud Ratios')\n",
    "ax[0].set_xlabel('Client')\n",
    "ax[0].set_ylabel('Fraud Ratio')\n",
    "\n",
    "ax[1].bar(client_names, test_fraud_ratios, color='green')\n",
    "ax[1].set_title('Testing Fraud Ratios')\n",
    "ax[1].set_xlabel('Client')\n",
    "ax[1].set_ylabel('Fraud Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Client Data Distributions\n",
    "\n",
    "Let's visualize how the data is distributed across clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud ratio distribution across clients\n",
    "client_names = []\n",
    "train_fraud_ratios = []\n",
    "test_fraud_ratios = []\n",
    "train_sizes = []\n",
    "test_sizes = []\n",
    "\n",
    "for client in client_datasets:\n",
    "    client_names.append(client['name'])\n",
    "    train_fraud_ratios.append(client['train']['FLAG'].mean() if len(client['train']) > 0 else 0)\n",
    "    test_fraud_ratios.append(client['test']['FLAG'].mean() if len(client['test']) > 0 else 0)\n",
    "    train_sizes.append(len(client['train']))\n",
    "    test_sizes.append(len(client['test']))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].bar(client_names, train_fraud_ratios, color='blue')\n",
    "ax[0].set_title('Training Fraud Ratios')\n",
    "ax[0].set_xlabel('Client')\n",
    "ax[0].set_ylabel('Fraud Ratio')\n",
    "\n",
    "ax[1].bar(client_names, test_fraud_ratios, color='green')\n",
    "ax[1].set_title('Testing Fraud Ratios')\n",
    "ax[1].set_xlabel('Client')\n",
    "ax[1].set_ylabel('Fraud Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Client Data Distributions\n",
    "\n",
    "Let's visualize how the data is distributed across clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud ratio distribution across clients\n",
    "client_names = []\n",
    "train_fraud_ratios = []\n",
    "test_fraud_ratios = []\n",
    "train_sizes = []\n",
    "test_sizes = []\n",
    "\n",
    "for client in client_datasets:\n",
    "    client_names.append(client['name'])\n",
    "    train_fraud_ratios.append(client['train']['FLAG'].mean() if len(client['train']) > 0 else 0)\n",
    "    test_fraud_ratios.append(client['test']['FLAG'].mean() if len(client['test']) > 0 else 0)\n",
    "    train_sizes.append(len(client['train']))\n",
    "    test_sizes.append(len(client['test']))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].bar(client_names, train_fraud_ratios, color='blue')\n",
    "ax[0].set_title('Training Fraud Ratios')\n",
    "ax[0].set_xlabel('Client')\n",
    "ax[0].set_ylabel('Fraud Ratio')\n",
    "\n",
    "ax[1].bar(client_names, test_fraud_ratios, color='green')\n",
    "ax[1].set_title('Testing Fraud Ratios')\n",
    "ax[1].set_xlabel('Client')\n",
    "ax[1].set_ylabel('Fraud Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Client Data Distributions\n",
    "\n",
    "Let's visualize how the data is distributed across clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud ratio distribution across clients\n",
    "client_names = []\n",
    "train_fraud_ratios = []\n",
    "test_fraud_ratios = []\n",
    "train_sizes = []\n",
    "test_sizes = []\n",
    "\n",
    "for client in client_datasets:\n",
    "    client_names.append(client['name'])\n",
    "    train_fraud_ratios.append(client['train']['FLAG'].mean() if len(client['train']) > 0 else 0)\n",
    "    test_fraud_ratios.append(client['test']['FLAG'].mean() if len(client['test']) > 0 else 0)\n",
    "    train_sizes.append(len(client['train']))\n",
    "    test_sizes.append(len(client['test']))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].bar(client_names, train_fraud_ratios, color='blue')\n",
    "ax[0].set_title('Training Fraud Ratios')\n",
    "ax[0].set_xlabel('Client')\n",
    "ax[0].set_ylabel('Fraud Ratio')\n",
    "\n",
    "ax[1].bar(client_names, test_fraud_ratios, color='green')\n",
    "ax[1].set_title('Testing Fraud Ratios')\n",
    "ax[1].set_xlabel('Client')\n",
    "ax[1].set_ylabel('Fraud Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Client Data Distributions\n",
    "\n",
    "Let's visualize how the data is distributed across clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud ratio distribution across clients\n",
    "client_names = []\n",
    "train_fraud_ratios = []\n",
    "test_fraud_ratios = []\n",
    "train_sizes = []\n",
    "test_sizes = []\n",
    "\n",
    "for client in client_datasets:\n",
    "    client_names.append(client['name'])\n",
    "    train_fraud_ratios.append(client['train']['FLAG'].mean() if len(client['train']) > 0 else 0)\n",
    "    test_fraud_ratios.append(client['test']['FLAG'].mean() if len(client['test']) > 0 else 0)\n",
    "    train_sizes.append(len(client['train']))\n",
    "    test_sizes.append(len(client['test']))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].bar(client_names, train_fraud_ratios, color='blue')\n",
    "ax[0].set_title('Training Fraud Ratios')\n",
    "ax[0].set_xlabel('Client')\n",
    "ax[0].set_ylabel('Fraud Ratio')\n",
    "\n",
    "ax[1].bar(client_names, test_fraud_ratios, color='green')\n",
    "ax[1].set_title('Testing Fraud Ratios')\n",
    "ax[1].set_xlabel('Client')\n",
    "ax[1].set_ylabel('Fraud Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Client Data Distributions\n",
    "\n",
    "Let's visualize how the data is distributed across clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud ratio distribution across clients\n",
    "client_names = []\n",
    "train_fraud_ratios = []\n",
    "test_fraud_ratios = []\n",
    "train_sizes = []\n",
    "test_sizes = []\n",
    "\n",
    "for client in client_datasets:\n",
    "    client_names.append(client['name'])\n",
    "    train_fraud_ratios.append(client['train']['FLAG'].mean() if len(client['train']) > 0 else 0)\n",
    "    test_fraud_ratios.append(client['test']['FLAG'].mean() if len(client['test']) > 0 else 0)\n",
    "    train_sizes.append(len(client['train']))\n",
    "    test_sizes.append(len(client['test']))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].bar(client_names, train_fraud_ratios, color='blue')\n",
    "ax[0].set_title('Training Fraud Ratios')\n",
    "ax[0].set_xlabel('Client')\n",
    "ax[0].set_ylabel('Fraud Ratio')\n",
    "\n",
    "ax[1].bar(client_names, test_fraud_ratios, color='green')\n",
    "ax[1].set_title('Testing Fraud Ratios')\n",
    "ax[1].set_xlabel('Client')\n",
    "ax[1].set_ylabel('Fraud Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Client Data Distributions\n",
    "\n",
    "Let's visualize how the data is distributed across clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud ratio distribution across clients\n",
    "client_names = []\n",
    "train_fraud_ratios = []\n",
    "test_fraud_ratios = []\n",
    "train_sizes = []\n",
    "test_sizes = []\n",
    "\n",
    "for client in client_datasets:\n",
    "    client_names.append(client['name'])\n",
    "    train_fraud_ratios.append(client['train']['FLAG'].mean() if len(client['train']) > 0 else 0)\n",
    "    test_fraud_ratios.append(client['test']['FLAG'].mean() if len(client['test']) > 0 else 0)\n",
    "    train_sizes.append(len(client['train']))\n",
    "    test_sizes.append(len(client['test']))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].bar(client_names, train_fraud_ratios, color='blue')\n",
    "ax[0].set_title('Training Fraud Ratios')\n",
    "ax[0].set_xlabel('Client')\n",
    "ax[0].set_ylabel('Fraud Ratio')\n",
    "\n",
    "ax[1].bar(client_names, test_fraud_ratios, color='green')\n",
    "ax[1].set_title('Testing Fraud Ratios')\n",
    "ax[1].set_xlabel('Client')\n",
    "ax[1].set_ylabel('Fraud Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Client Data Distributions\n",
    "\n",
    "Let's visualize how the data is distributed across clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud ratio distribution across clients\n",
    "client_names = []\n",
    "train_fraud_ratios = []\n",
    "test_fraud_ratios = []\n",
    "train_sizes = []\n",
    "test_sizes = []\n",
    "\n",
    "for client in client_datasets:\n",
    "    client_names.append(client['name'])\n",
    "    train_fraud_ratios.append(client['train']['FLAG'].mean() if len(client['train']) > 0 else 0)\n",
    "    test_fraud_ratios.append(client['test']['FLAG'].mean() if len(client['test']) > 0 else 0)\n",
    "    train_sizes.append(len(client['train']))\n",
    "    test_sizes.append(len(client['test']))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].bar(client_names, train_fraud_ratios, color='blue')\n",
    "ax[0].set_title('Training Fraud Ratios')\n",
    "ax[0].set_xlabel('Client')\n",
    "ax[0].set_ylabel('Fraud Ratio')\n",
    "\n",
    "ax[1].bar(client_names, test_fraud_ratios, color='green')\n",
    "ax[1].set_title('Testing Fraud Ratios')\n",
    "ax[1].set_xlabel('Client')\n",
    "ax[1].set_ylabel('Fraud Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Client Data Distributions\n",
    "\n",
    "Let's visualize how the data is distributed across clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud ratio distribution across clients\n",
    "client_names = []\n",
    "train_fraud_ratios = []\n",
    "test_fraud_ratios = []\n",
    "train_sizes = []\n",
    "test_sizes = []\n",
    "\n",
    "for client in client_datasets:\n",
    "    client_names.append(client['name'])\n",
    "    train_fraud_ratios.append(client['train']['FLAG'].mean() if len(client['train']) > 0 else 0)\n",
    "    test_fraud_ratios.append(client['test']['FLAG'].mean() if len(client['test']) > 0 else 0)\n",
    "    train_sizes.append(len(client['train']))\n",
    "    test_sizes.append(len(client['test']))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].bar(client_names, train_fraud_ratios, color='blue')\n",
    "ax[0].set_title('Training Fraud Ratios')\n",
    "ax[0].set_xlabel('Client')\n",
    "ax[0].set_ylabel('Fraud Ratio')\n",
    "\n",
    "ax[1].bar(client_names, test_fraud_ratios, color='green')\n",
    "ax[1].set_title('Testing Fraud Ratios')\n",
    "ax[1].set_xlabel('Client')\n",
    "ax[1].set_ylabel('Fraud Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Client Data Distributions\n",
    "\n",
    "Let's visualize how the data is distributed across clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud ratio distribution across clients\n",
    "client_names = []\n",
    "train_fraud_ratios = []\n",
    "test_fraud_ratios = []\n",
    "train_sizes = []\n",
    "test_sizes = []\n",
    "\n",
    "for client in client_datasets:\n",
    "    client_names.append(client['name'])\n",
    "    train_fraud_ratios.append(client['train']['FLAG'].mean() if len(client['train']) > 0 else 0)\n",
    "    test_fraud_ratios.append(client['test']['FLAG'].mean() if len(client['test']) > 0 else 0)\n",
    "    train_sizes.append(len(client['train']))\n",
    "    test_sizes.append(len(client['test']))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].bar(client_names, train_fraud_ratios, color='blue')\n",
    "ax[0].set_title('Training Fraud Ratios')\n",
    "ax[0].set_xlabel('Client')\n",
    "ax[0].set_ylabel('Fraud Ratio')\n",
    "\n",
    "ax[1].bar(client_names, test_fraud_ratios, color='green')\n",
    "ax[1].set_title('Testing Fraud Ratios')\n",
    "ax[1].set_xlabel('Client')\n",
    "ax[1].set_ylabel('Fraud Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Client Data Distributions\n",
    "\n",
    "Let's visualize how the data is distributed across clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud ratio distribution across clients\n",
    "client_names = []\n",
    "train_fraud_ratios = []\n",
    "test_fraud_ratios = []\n",
    "train_sizes = []\n",
    "test_sizes = []\n",
    "\n",
    "for client in client_datasets:\n",
    "    client_names.append(client['name'])\n",
    "    train_fraud_ratios.append(client['train']['FLAG'].mean() if len(client['train']) > 0 else 0)\n",
    "    test_fraud_ratios.append(client['test']['FLAG'].mean() if len(client['test']) > 0 else 0)\n",
    "    train_sizes.append(len(client['train']))\n",
    "    test_sizes.append(len(client['test']))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].bar(client_names, train_fraud_ratios, color='blue')\n",
    "ax[0].set_title('Training Fraud Ratios')\n",
    "ax[0].set_xlabel('Client')\n",
    "ax[0].set_ylabel('Fraud Ratio')\n",
    "\n",
    "ax[1].bar(client_names, test_fraud_ratios, color='green')\n",
    "ax[1].set_title('Testing Fraud Ratios')\n",
    "ax[1].set_xlabel('Client')\n",
    "ax[1].set_ylabel('Fraud Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Client Data Distributions\n",
    "\n",
    "Let's visualize how the data is distributed across clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud ratio distribution across clients\n",
    "client_names = []\n",
    "train_fraud_ratios = []\n",
    "test_fraud_ratios = []\n",
    "train_sizes = []\n",
    "test_sizes = []\n",
    "\n",
    "for client in client_datasets:\n",
    "    client_names.append(client['name'])\n",
    "    train_fraud_ratios.append(client['train']['FLAG'].mean() if len(client['train']) > 0 else 0)\n",
    "    test_fraud_ratios.append(client['test']['FLAG'].mean() if len(client['test']) > 0 else 0)\n",
    "    train_sizes.append(len(client['train']))\n",
    "    test_sizes.append(len(client['test']))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].bar(client_names, train_fraud_ratios, color='blue')\n",
    "ax[0].set_title('Training Fraud Ratios')\n",
    "ax[0].set_xlabel('Client')\n",
    "ax[0].set_ylabel('Fraud Ratio')\n",
    "\n",
    "ax[1].bar(client_names, test_fraud_ratios, color='green')\n",
    "ax[1].set_title('Testing Fraud Ratios')\n",
    "ax[1].set_xlabel('Client')\n",
    "ax[1].set_ylabel('Fraud Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Client Data Distributions\n",
    "\n",
    "Let's visualize how the data is distributed across clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud ratio distribution across clients\n",
    "client_names = []\n",
    "train_fraud_ratios = []\n",
    "test_fraud_ratios = []\n",
    "train_sizes = []\n",
    "test_sizes = []\n",
    "\n",
    "for client in client_datasets:\n",
    "    client_names.append(client['name'])\n",
    "    train_fraud_ratios.append(client['train']['FLAG'].mean() if len(client['train']) > 0 else 0)\n",
    "    test_fraud_ratios.append(client['test']['FLAG'].mean() if len(client['test']) > 0 else 0)\n",
    "    train_sizes.append(len(client['train']))\n",
    "    test_sizes.append(len(client['test']))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].bar(client_names, train_fraud_ratios, color='blue')\n",
    "ax[0].set_title('Training Fraud Ratios')\n",
    "ax[0].set_xlabel('Client')\n",
    "ax[0].set_ylabel('Fraud Ratio')\n",
    "\n",
    "ax[1].bar(client_names, test_fraud_ratios, color='green')\n",
    "ax[1].set_title('Testing Fraud Ratios')\n",
    "ax[1].set_xlabel('Client')\n",
    "ax[1].set_ylabel('Fraud Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Client Data Distributions\n",
    "\n",
    "Let's visualize how the data is distributed across clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud ratio distribution across clients\n",
    "client_names = []\n",
    "train_fraud_ratios = []\n",
    "test_fraud_ratios = []\n",
    "train_sizes = []\n",
    "test_sizes = []\n",
    "\n",
    "for client in client_datasets:\n",
    "    client_names.append(client['name'])\n",
    "    train_fraud_ratios.append(client['train']['FLAG'].mean() if len(client['train']) > 0 else 0)\n",
    "    test_fraud_ratios.append(client['test']['FLAG'].mean() if len(client['test']) > 0 else 0)\n",
    "    train_sizes.append(len(client['train']))\n",
    "    test_sizes.append(len(client['test']))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].bar(client_names, train_fraud_ratios, color='blue')\n",
    "ax[0].set_title('Training Fraud Ratios')\n",
    "ax[0].set_xlabel('Client')\n",
    "ax[0].set_ylabel('Fraud Ratio')\n",
    "\n",
    "ax[1].bar(client_names, test_fraud_ratios, color='green')\n",
    "ax[1].set_title('Testing Fraud Ratios')\n",
    "ax[1].set_xlabel('Client')\n",
    "ax[1].set_ylabel('Fraud Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Client Data Distributions\n",
    "\n",
    "Let's visualize how the data is distributed across clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud ratio distribution across clients\n",
    "client_names = []\n",
    "train_fraud_ratios = []\n",
    "test_fraud_ratios = []\n",
    "train_sizes = []\n",
    "test_sizes = []\n",
    "\n",
    "for client in client_datasets:\n",
    "    client_names.append(client['name'])\n",
    "    train_fraud_ratios.append(client['train']['FLAG'].mean() if len(client['train']) > 0 else 0)\n",
    "    test_fraud_ratios.append(client['test']['FLAG'].mean() if len(client['test']) > 0 else 0)\n",
    "    train_sizes.append(len(client['train']))\n",
    "    test_sizes.append(len(client['test']))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].bar(client_names, train_fraud_ratios, color='blue')\n",
    "ax[0].set_title('Training Fraud Ratios')\n",
    "ax[0].set_xlabel('Client')\n",
    "ax[0].set_ylabel('Fraud Ratio')\n",
    "\n",
    "ax[1].bar(client_names, test_fraud_ratios, color='green')\n",
    "ax[1].set_title('Testing Fraud Ratios')\n",
    "ax[1].set_xlabel('Client')\n",
    "ax[1].set_ylabel('Fraud Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Client Data Distributions\n",
    "\n",
    "Let's visualize how the data is distributed across clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud ratio distribution across clients\n",
    "client_names = []\n",
    "train_fraud_ratios = []\n",
    "test_fraud_ratios = []\n",
    "train_sizes = []\n",
    "test_sizes = []\n",
    "\n",
    "for client in client_datasets:\n",
    "    client_names.append(client['name'])\n",
    "    train_fraud_ratios.append(client['train']['FLAG'].mean() if len(client['train']) > 0 else 0)\n",
    "    test_fraud_ratios.append(client['test']['FLAG'].mean() if len(client['test']) > 0 else 0)\n",
    "    train_sizes.append(len(client['train']))\n",
    "    test_sizes.append(len(client['test']))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].bar(client_names, train_fraud_ratios, color='blue')\n",
    "ax[0].set_title('Training Fraud Ratios')\n",
    "ax[0].set_xlabel('Client')\n",
    "ax[0].set_ylabel('Fraud Ratio')\n",
    "\n",
    "ax[1].bar(client_names, test_fraud_ratios, color='green')\n",
    "ax[1].set_title('Testing Fraud Ratios')\n",
    "ax[1].set_xlabel('Client')\n",
    "ax[1].set_ylabel('Fraud Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Client Data Distributions\n",
    "\n",
    "Let's visualize how the data is distributed across clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud ratio distribution across clients\n",
    "client_names = []\n",
    "train_fraud_ratios = []\n",
    "test_fraud_ratios = []\n",
    "train_sizes = []\n",
    "test_sizes = []\n",
    "\n",
    "for client in client_datasets:\n",
    "    client_names.append(client['name'])\n",
    "    train_fraud_ratios.append(client['train']['FLAG'].mean() if len(client['train']) > 0 else 0)\n",
    "    test_fraud_ratios.append(client['test']['FLAG'].mean() if len(client['test']) > 0 else 0)\n",
    "    train_sizes.append(len(client['train']))\n",
    "    test_sizes.append(len(client['test']))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].bar(client_names, train_fraud_ratios, color='blue')\n",
    "ax[0].set_title('Training Fraud Ratios')\n",
    "ax[0].set_xlabel('Client')\n",
    "ax[0].set_ylabel('Fraud Ratio')\n",
    "\n",
    "ax[1].bar(client_names, test_fraud_ratios, color='green')\n",
    "ax[1].set_title('Testing Fraud Ratios')\n",
    "ax[1].set_xlabel('Client')\n",
    "ax[1].set_ylabel('Fraud Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Client Data Distributions\n",
    "\n",
    "Let's visualize how the data is distributed across clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud ratio distribution across clients\n",
    "client_names = []\n",
    "train_fraud_ratios = []\n",
    "test_fraud_ratios = []\n",
    "train_sizes = []\n",
    "test_sizes = []\n",
    "\n",
    "for client in client_datasets:\n",
    "    client_names.append(client['name'])\n",
    "    train_fraud_ratios.append(client['train']['FLAG'].mean() if len(client['train']) > 0 else 0)\n",
    "    test_fraud_ratios.append(client['test']['FLAG'].mean() if len(client['test']) > 0 else 0)\n",
    "    train_sizes.append(len(client['train']))\n",
    "    test_sizes.append(len(client['test']))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].bar(client_names, train_fraud_ratios, color='blue')\n",
    "ax[0].set_title('Training Fraud Ratios')\n",
    "ax[0].set_xlabel('Client')\n",
    "ax[0].set_ylabel('Fraud Ratio')\n",
    "\n",
    "ax[1].bar(client_names, test_fraud_ratios, color='green')\n",
    "ax[1].set_title('Testing Fraud Ratios')\n",
    "ax[1].set_xlabel('Client')\n",
    "ax[1].set_ylabel('Fraud Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Client Data Distributions\n",
    "\n",
    "Let's visualize how the data is distributed across clients."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
